{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diabetes Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "This dataset is originally from the National Institute of Diabetes and Digestive and Kidney Diseases. The objective of the dataset is to diagnostically predict whether or not a patient has diabetes, based on certain diagnostic measurements included in the dataset. Several constraints were placed on the selection of these instances from a larger database. In particular, all patients here are females at least 21 years old of Pima Indian heritage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So what is diabetes and what leads to someone getting it? The following is from the Centers for Disease Control and Prevention (CDC).  \n",
    "\n",
    "Insulin is a hormone made by your pancreas that acts like a key to let blood sugar into the cells in your body for use as energy. If you have type 2 diabetes, cells don’t respond normally to insulin; this is called insulin resistance. Your pancreas makes more insulin to try to get cells to respond. Eventually your pancreas can’t keep up, and your blood sugar rises, setting the stage for prediabetes and type 2 diabetes. High blood sugar is damaging to the body and can cause other serious health problems, such as heart disease, vision loss, and kidney disease.\n",
    "\n",
    "Type 2 diabetes symptoms often develop over several years and can go on for a long time without being noticed (sometimes there aren’t any noticeable symptoms at all). Because symptoms can be hard to spot, it’s important to know the risk factors and to see your doctor to get your blood sugar tested if you have any of them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data set we will be using is the PIMA Indian Diabetes data set. The PIMA Indians are a tribe in Arizona and more about their history can be found here https://en.wikipedia.org/wiki/Pima_people\n",
    "\n",
    "The data set consist of females over the age of 21. There are a total of 9 features including outcome, which is what we will be trying to predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Number of times pregnant\n",
    "2. Plasma glucose concentration a 2 hours in an oral glucose tolerance test\n",
    "3. Diastolic blood pressure (mm Hg)\n",
    "4. Triceps skin fold thickness (mm)\n",
    "5. 2-Hour serum insulin (mu U/ml)\n",
    "6. Body mass index (weight in kg/(height in m)^2)\n",
    "7. Diabetes pedigree function(A function that scores the likelihood of diabetes based on family history)\n",
    "8. Age (years)\n",
    "9. Outcome (0 or 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the necessary python libraries\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the data\n",
    "diabetes_data = pd.read_csv(r'diabetes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading the dataset\n",
    "diabetes_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Observing the shape of dataframe\n",
    "\n",
    "print(diabetes_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it is observed above that we have 768 rows and 9 columns.   \n",
    "The first 8 columns represent the features and the last column represent the target/label."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic EDA & statistical analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploratory Data Analysis or EDA , is an important step to be performed in Data Science projects.\n",
    "EDA is generally the process of visualising datasets to find out different patterns in the datasets, analyzing the anomalies behaviour of the datasets and building assumptions or hypothesis based on the understanding of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the describe we will try and gain more insights of our data:\n",
    "#for descriptive statistics of the data \n",
    "diabetes_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For complete information about the data\n",
    "diabetes_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for datatypes in the data\n",
    "diabetes_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding missing values\n",
    "print(diabetes_data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To check if there are any special characters in place of values \n",
    "for i in diabetes_data.columns:\n",
    "    print({i:diabetes_data[i].unique()})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no missing values or any unique values available in the data but, there are some values which are termed as zero(0). \n",
    "From the above columns some columns such as-\n",
    "1. Glucose\n",
    "2. BloodPressure\n",
    "3. SkinThickness\n",
    "4. Insulin\n",
    "5. BMI,  \n",
    "have zero values which does not make any sense as these values can't be 0.  \n",
    "So,we will consider these zero values as missing values.  \n",
    "\n",
    "It is better to replace zeros with NaN since after that counting them would be easier and zeros need to be replaced with some suitable values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "diabetes_data_df = diabetes_data.copy(deep = True)\n",
    "diabetes_data_df[['Glucose','BloodPressure',\n",
    "                    'SkinThickness','Insulin','BMI']] = diabetes_data_df[['Glucose','BloodPressure','SkinThickness',\n",
    "                                                                            'Insulin','BMI']].replace(0,np.nan)\n",
    "\n",
    "## showing the count of Nans\n",
    "print(diabetes_data_df.isnull().sum()/len(diabetes_data_df)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To fill up these NaN values understanding the data distribution is necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = diabetes_data_df.hist(figsize = (20,20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imputing NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes_data_df['Glucose'].fillna(diabetes_data_df['Glucose'].mean(), inplace = True)\n",
    "\n",
    "diabetes_data_df['BloodPressure'].fillna(diabetes_data_df['BloodPressure'].mean(), inplace = True)\n",
    "\n",
    "diabetes_data_df['SkinThickness'].fillna(diabetes_data_df['SkinThickness'].median(), inplace = True)\n",
    "\n",
    "diabetes_data_df['Insulin'].fillna(diabetes_data_df['Insulin'].median(), inplace = True)\n",
    "\n",
    "diabetes_data_df['BMI'].fillna(diabetes_data_df['BMI'].median(), inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes_data_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting after removal removal of NaN values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = diabetes_data_df.hist(figsize = (20,20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Heatmap map for unclean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "corr = diabetes_data.corr()\n",
    "plt.figure(figsize=(8,8))\n",
    "sns.heatmap(corr, vmin=-1.0,vmax=1.0,annot=True)\n",
    "plt.yticks(rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Heatmap for clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "corr = diabetes_data_df.corr()\n",
    "plt.figure(figsize=(8,8))\n",
    "sns.heatmap(corr, vmin=-1.0,vmax=1.0,annot=True)\n",
    "plt.yticks(rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()\n",
    "price_plot=diabetes_data_df['Outcome'].value_counts().plot(kind='bar')\n",
    "plt.xlabel('Outcome')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From the above graph it is understood that the data is biased towards datapoints having the outcome value as 0 which  means that the non-diabetic patients were more in number as compared to that of the diabetic patients."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating X & Y variables  for predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create X & Y \n",
    "X = diabetes_data_df.values[:,0:-1]\n",
    "Y = diabetes_data_df.values[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling the X variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As there are different feature variables in X, it can have a possibility of giving more importance to the variables having greater range and give less important to variables having small range which is not suitable.  \n",
    "So to overcome this problem scaling is done on the all variables in X, as it will bring all the variables in a same range.  \n",
    "This will help us to use distance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler=StandardScaler()\n",
    "\n",
    "scaler.fit(X)\n",
    "\n",
    "X = scaler.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train_test_splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split  #<1000=in range of 80-20  &  >1000=in range of 70-30\n",
    "\n",
    "#Split the data into test and train\n",
    "X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.2,random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "#create a model\n",
    "classifier=LogisticRegression()\n",
    "#fitting training data to the model\n",
    "classifier.fit(X_train,Y_train)\n",
    "\n",
    "Y_pred=classifier.predict(X_test)\n",
    "print(Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(suppress= True)\n",
    "Y_pred_prob=classifier.predict_proba(X_test)\n",
    "Y_pred_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "\n",
    "cfm=confusion_matrix(Y_test,Y_pred)\n",
    "sns.heatmap(cfm, annot=True, fmt='g', cbar=False, cmap='BuPu')\n",
    "plt.xlabel('Predicted Values')\n",
    "plt.ylabel('Actual Values')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print(\"Classification report:\")\n",
    "\n",
    "print(classification_report(Y_test,Y_pred))\n",
    "\n",
    "acc=accuracy_score(Y_test,Y_pred)\n",
    "print(\"Accuracy of the model: \",acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train Score(Log):\",classifier.score(X_train,Y_train))\n",
    "print(\"Test Score(Log):\",classifier.score(X_test,Y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicting using the Decision_Tree_Classifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "model_DecisionTree = DecisionTreeClassifier(criterion=\"gini\",random_state=10)\n",
    "\n",
    "#fit the model on the data and predict the values\n",
    "model_DecisionTree.fit(X_train,Y_train)\n",
    "\n",
    "Y_pred = model_DecisionTree.predict(X_test)\n",
    "#print(Y_pred)\n",
    "#print(list(zip(Y_test,Y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "\n",
    "cfm=confusion_matrix(Y_test,Y_pred)\n",
    "sns.heatmap(cfm, annot=True, fmt='g', cbar=False, cmap='BuPu')\n",
    "plt.xlabel('Predicted Values')\n",
    "plt.ylabel('Actual Values')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print(\"Classification report:\")\n",
    "\n",
    "print(classification_report(Y_test,Y_pred))\n",
    "\n",
    "acc=accuracy_score(Y_test,Y_pred)\n",
    "print(\"Accuracy of the model: \",acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train Score(Log):\",model_DecisionTree.score(X_train,Y_train))\n",
    "print(\"Test Score(Log):\",model_DecisionTree.score(X_test,Y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the Type II errors or we can say the patients who were diabetic but were detected as non - diabetic were still in no but still we can see the recall value was seemed to be inclined more towards \"0\" i.e. the patients who were non-diabetic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization techniques - Handling Imbalanced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes_data_df.Outcome.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "# Separate majority and minority classes\n",
    "df_majority = diabetes_data_df[diabetes_data_df.Outcome==0]\n",
    "df_minority = diabetes_data_df[diabetes_data_df.Outcome==1]\n",
    "\n",
    "# Upsample minority class\n",
    "df_minority_upsampled = resample(df_minority,\n",
    "                                 replace=True,     # sample with replacement\n",
    "                                 n_samples=450,    # to match majority class\n",
    "                                 random_state=10) # reproducible results\n",
    "\n",
    "# Combine majority class with upsampled minority class\n",
    "df_upsampled = pd.concat([df_majority, df_minority_upsampled])\n",
    "\n",
    "# Display new class counts\n",
    "print(df_upsampled.Outcome.value_counts())\n",
    "df_upsampled.Outcome.value_counts().plot(kind=\"pie\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df_upsampled.values[:,:-1]\n",
    "Y=df_upsampled.values[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler=StandardScaler()\n",
    "scaler.fit(X)\n",
    "X=scaler.transform(X)\n",
    "#X=scaler.fit_transform(X)\n",
    "#print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#split the data into test and train\n",
    "X_train, X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.2,random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from Logistic Regression.\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "#create a model object\n",
    "lr=LogisticRegression()\n",
    "#fitting training data to the model\n",
    "lr.fit(X_train,Y_train)\n",
    "\n",
    "Y_pred=lr.predict(X_test)\n",
    "print(Y_pred)\n",
    "#print(list(zip(Y_test,Y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "\n",
    "cfm=confusion_matrix(Y_test,Y_pred)\n",
    "sns.heatmap(cfm, annot=True, fmt='g', cbar=False, cmap='BuPu')\n",
    "plt.xlabel('Predicted Values')\n",
    "plt.ylabel('Actual Values')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print(\"Classification report:\")\n",
    "\n",
    "print(classification_report(Y_test,Y_pred))\n",
    "\n",
    "acc=accuracy_score(Y_test,Y_pred)\n",
    "print(\"Accuracy of the model: \",acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicting using the Decision Tree_Classifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "model_DecisionTree=DecisionTreeClassifier(criterion=\"gini\",random_state=10)\n",
    "\n",
    "\n",
    "#fit the model on the data and predict the values\n",
    "model_DecisionTree.fit(X_train,Y_train)\n",
    "Y_pred=model_DecisionTree.predict(X_test)\n",
    "#print(Y_pred)\n",
    "#print(list(zip(Y_test,Y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "\n",
    "cfm=confusion_matrix(Y_test,Y_pred)\n",
    "sns.heatmap(cfm, annot=True, fmt='g', cbar=False, cmap='BuPu')\n",
    "plt.xlabel('Predicted Values')\n",
    "plt.ylabel('Actual Values')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print(\"Classification report:\")\n",
    "\n",
    "print(classification_report(Y_test,Y_pred))\n",
    "\n",
    "acc=accuracy_score(Y_test,Y_pred)\n",
    "print(\"Accuracy of the model: \",acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "# Separate majority and minority classes\n",
    "df_majority = diabetes_data_df[diabetes_data_df.Outcome==0]\n",
    "df_minority = diabetes_data_df[diabetes_data_df.Outcome==1]\n",
    "\n",
    "# Upsample minority class\n",
    "df_majority_downsampled = resample(df_majority,\n",
    "                                 replace=True,     # sample with replacement\n",
    "                                 n_samples=250,    # to match majority class\n",
    "                                 random_state=10) # reproducible results\n",
    "\n",
    "# Combine majority class with upsampled minority class\n",
    "df_downsampled = pd.concat([df_minority, df_majority_downsampled])\n",
    "\n",
    "# Display new class counts\n",
    "print(df_downsampled.Outcome.value_counts())\n",
    "df_downsampled.Outcome.value_counts().plot(kind=\"pie\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df_downsampled.values[:,:-1]\n",
    "Y=df_downsampled.values[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler=StandardScaler()\n",
    "scaler.fit(X)\n",
    "X=scaler.transform(X)\n",
    "#X=scaler.fit_transform(X)\n",
    "#print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#split the data into test and train\n",
    "X_train, X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.2,random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from Logistic Regression.\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "#create a model object\n",
    "lr=LogisticRegression()\n",
    "#fitting training data to the model\n",
    "lr.fit(X_train,Y_train)\n",
    "\n",
    "Y_pred=lr.predict(X_test)\n",
    "print(Y_pred)\n",
    "#print(list(zip(Y_test,Y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "\n",
    "cfm=confusion_matrix(Y_test,Y_pred)\n",
    "sns.heatmap(cfm, annot=True, fmt='g', cbar=False, cmap='BuPu')\n",
    "plt.xlabel('Predicted Values')\n",
    "plt.ylabel('Actual Values')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print(\"Classification report:\")\n",
    "\n",
    "print(classification_report(Y_test,Y_pred))\n",
    "\n",
    "acc=accuracy_score(Y_test,Y_pred)\n",
    "print(\"Accuracy of the model: \",acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicting using the Decision Tree_Classifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "model_DecisionTree=DecisionTreeClassifier(criterion=\"gini\",random_state=10)\n",
    "\n",
    "\n",
    "#fit the model on the data and predict the values\n",
    "model_DecisionTree.fit(X_train,Y_train)\n",
    "Y_pred=model_DecisionTree.predict(X_test)\n",
    "#print(Y_pred)\n",
    "#print(list(zip(Y_test,Y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "\n",
    "cfm=confusion_matrix(Y_test,Y_pred)\n",
    "sns.heatmap(cfm, annot=True, fmt='g', cbar=False, cmap='BuPu')\n",
    "plt.xlabel('Predicted Values')\n",
    "plt.ylabel('Actual Values')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print(\"Classification report:\")\n",
    "\n",
    "print(classification_report(Y_test,Y_pred))\n",
    "\n",
    "acc=accuracy_score(Y_test,Y_pred)\n",
    "print(\"Accuracy of the model: \",acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=diabetes_data_df.values[:,:-1]      \n",
    "Y=diabetes_data_df.values[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler=StandardScaler()\n",
    "scaler.fit(X)\n",
    "X=scaler.transform(X)\n",
    "#X=scaler.fit_transform(X)\n",
    "#print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#split the data into test and train\n",
    "X_train, X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.2,random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(Y_train[Y_train==1])) # minority\n",
    "print(len(Y_train[Y_train==0])) #majority\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?sm.fit_resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Before OverSampling, counts of label '1': \", (sum(Y_train == 1)))\n",
    "print(\"Before OverSampling, counts of label '0': \", (sum(Y_train == 0)))\n",
    "  \n",
    "# import SMOTE from imblearn library\n",
    "from imblearn.over_sampling import SMOTE\n",
    "sm = SMOTE(random_state = 10)\n",
    "X_train_res, Y_train_res = sm.fit_resample(X_train, Y_train)\n",
    "  \n",
    "print('After OverSampling, the shape of train_X: ', (X_train_res.shape))\n",
    "print('After OverSampling, the shape of train_y: ', (Y_train_res.shape))\n",
    "  \n",
    "print(\"After OverSampling, counts of label '1': \", (sum(Y_train_res == 1)))\n",
    "print(\"After OverSampling, counts of label '0': \", (sum(Y_train_res == 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from Logistic Regression.\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "#create a model object\n",
    "lr=LogisticRegression()\n",
    "#fitting training data to the model\n",
    "lr.fit(X_train_res,Y_train_res)\n",
    "\n",
    "Y_pred=lr.predict(X_test)\n",
    "print(Y_pred)\n",
    "#print(list(zip(Y_test,Y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "\n",
    "cfm=confusion_matrix(Y_test,Y_pred)\n",
    "sns.heatmap(cfm, annot=True, fmt='g', cbar=False, cmap='BuPu')\n",
    "plt.xlabel('Predicted Values')\n",
    "plt.ylabel('Actual Values')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print(\"Classification report:\")\n",
    "\n",
    "print(classification_report(Y_test,Y_pred))\n",
    "\n",
    "acc=accuracy_score(Y_test,Y_pred)\n",
    "print(\"Accuracy of the model: \",acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicting using the Decision Tree_Classifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "model_DecisionTree=DecisionTreeClassifier(criterion=\"gini\",random_state=10)\n",
    "\n",
    "\n",
    "#fit the model on the data and predict the values\n",
    "model_DecisionTree.fit(X_train,Y_train)\n",
    "Y_pred=model_DecisionTree.predict(X_test)\n",
    "#print(Y_pred)\n",
    "#print(list(zip(Y_test,Y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "\n",
    "cfm=confusion_matrix(Y_test,Y_pred)\n",
    "sns.heatmap(cfm, annot=True, fmt='g', cbar=False, cmap='BuPu')\n",
    "plt.xlabel('Predicted Values')\n",
    "plt.ylabel('Actual Values')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print(\"Classification report:\")\n",
    "\n",
    "print(classification_report(Y_test,Y_pred))\n",
    "\n",
    "acc=accuracy_score(Y_test,Y_pred)\n",
    "print(\"Accuracy of the model: \",acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
